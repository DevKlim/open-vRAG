{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VideoChat Lite on Colab: Cloud-Based Video Labeling\n",
    "\n",
    "This notebook demonstrates the core \"behind-the-scenes\" logic of the VideoChat application's **lite mode**, adapted to run directly in Google Colab. Instead of using local, GPU-intensive models, this workflow relies entirely on Google Cloud APIs (Google AI Studio or Vertex AI) for analysis.\n",
    "\n",
    "We will walk through:\n",
    "1.  **Environment Setup**: Downloading the application code and installing necessary packages.\n",
    "2.  **Authentication & Configuration**: Securely providing API keys and defining the target video.\n",
    "3.  **Asset Preparation**: Programmatically downloading and preparing a video, just like the web app does.\n",
    "4.  **Cloud-Based Labeling**: Calling the function that sends the video and context to the selected Google Cloud model for analysis.\n",
    "5.  **Result Processing**: Displaying the structured JSON labels returned by the model.\n",
    "\n",
    "**Requirements**:\n",
    "*   A Google Account to run this Colab notebook.\n",
    "*   A Google AI Studio API Key or a configured Google Cloud Platform (GCP) project for Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, we'll download all the necessary Python helper scripts and the list of required packages directly from the project's GitHub repository. Then, we'll install the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the raw files from the GitHub repository.\n",
    "# ‚û°Ô∏è Action Required: Replace with your actual repository's raw content URL.\n",
    "BASE_URL = \"https://raw.githubusercontent.com/DevKlim/open-vRAG/main/\"\n",
    "\n",
    "# Download all necessary source files (excluding app.py to avoid web server errors)\n",
    "print(\"Downloading required source files...\")\n",
    "!wget -q {BASE_URL}requirements-lite.txt\n",
    "!wget -q {BASE_URL}inference_logic.py\n",
    "!wget -q {BASE_URL}factuality_logic.py\n",
    "!wget -q {BASE_URL}labeling_logic.py\n",
    "!wget -q {BASE_URL}my_vision_process.py\n",
    "print(\"Downloads complete.\")\n",
    "\n",
    "# Install dependencies using pip (output is hidden for cleanliness)\n",
    "print(\"\\nInstalling dependencies...\")\n",
    "!pip install -r requirements-lite.txt > /dev/null\n",
    "print(\"Dependencies installed.\")\n",
    "\n",
    "# This allows running async code in a Jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete. You can now proceed to the next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "The following cell contains the core logic functions for video preparation and metadata generation, copied from `app.py`. This makes our notebook self-contained and avoids the error caused by importing the web server file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import csv\n",
    "import io\n",
    "import datetime\n",
    "import json\n",
    "import yt_dlp\n",
    "\n",
    "# Import modules we downloaded\n",
    "import inference_logic\n",
    "import factuality_logic\n",
    "from factuality_logic import parse_vtt\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# --- CroissantML Imports with error handling ---\n",
    "try:\n",
    "    from croissant import nodes as cnodes\n",
    "    from croissant import Metadata\n",
    "    from croissant.data_types import DataType\n",
    "    CROISSANT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    cnodes, Metadata, DataType, CROISSANT_AVAILABLE = None, None, None, False\n",
    "\n",
    "# --- Global variables and settings for our functions ---\n",
    "LITE_MODE = True\n",
    "progress_message = \"\"\n",
    "\n",
    "os.makedirs(\"videos\", exist_ok=True)\n",
    "os.makedirs(\"data/labels\", exist_ok=True)\n",
    "os.makedirs(\"metadata\", exist_ok=True)\n",
    "\n",
    "def progress_hook(d):\n",
    "    global progress_message\n",
    "    if d['status'] == 'downloading':\n",
    "        percent = d.get('_percent_str', 'N/A').strip()\n",
    "        speed = d.get('_speed_str', 'N/A').strip()\n",
    "        eta = d.get('_eta_str', 'N/A').strip()\n",
    "        progress_message = f\"Downloading: {percent} at {speed}, ETA: {eta}\"\n",
    "    elif d['status'] == 'finished':\n",
    "        progress_message = \"Download finished. Preparing video assets...\"\n",
    "\n",
    "async def run_subprocess_async(command: list[str]):\n",
    "    process = await asyncio.create_subprocess_exec(\n",
    "        *command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = await process.communicate()\n",
    "    if process.returncode != 0:\n",
    "        error_details = stderr.decode()\n",
    "        raise RuntimeError(f\"Process failed: {command}\\n{error_details}\")\n",
    "    return stdout.decode()\n",
    "\n",
    "async def prepare_video_assets_async(url: str) -> dict:\n",
    "    global progress_message\n",
    "    loop = asyncio.get_event_loop()\n",
    "    is_local_file = not (url.startswith((\"http://\", \"https://\")))\n",
    "\n",
    "    if is_local_file:\n",
    "        raise NotImplementedError(\"Local file processing is not set up for this notebook.\")\n",
    "\n",
    "    progress_message = \"starting video download...\"\n",
    "    ydl_opts = {\n",
    "        'format': 'best[ext=mp4]/best',\n",
    "        'outtmpl': 'videos/%(id)s.%(ext)s',\n",
    "        'progress_hooks': [progress_hook],\n",
    "        'writesubtitles': True, 'writeautomaticsub': True,\n",
    "        'subtitleslangs': ['en'], 'quiet': True, 'noplaylist': True,\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = await loop.run_in_executor(None, lambda: ydl.extract_info(url, download=True))\n",
    "        original_path = Path(ydl.prepare_filename(info))\n",
    "        video_id = info.get(\"id\")\n",
    "        transcript_path = next(Path(\"videos\").glob(f\"{video_id}*.en.vtt\"), None)\n",
    "        if not transcript_path:\n",
    "             transcript_path = next(Path(\"videos\").glob(f\"{video_id}*.vtt\"), None)\n",
    "        \n",
    "        caption_text = info.get(\"description\", info.get(\"title\", \"N/A\"))\n",
    "        clean_caption = caption_text.encode('ascii', 'ignore').decode('ascii').strip()\n",
    "        metadata = {\n",
    "            \"id\": info.get(\"id\", \"N/A\"),\n",
    "            \"link\": info.get(\"webpage_url\", url),\n",
    "            \"caption\": clean_caption,\n",
    "        }\n",
    "\n",
    "    sanitized_path = original_path.with_name(f\"{original_path.stem}_fixed.mp4\")\n",
    "    ffmpeg_cmd = [\"ffmpeg\", \"-i\", str(original_path), \"-c:v\", \"libx264\", \"-preset\", \"fast\", \"-crf\", \"23\", \"-c:a\", \"aac\", \"-y\", str(sanitized_path)]\n",
    "    await run_subprocess_async(ffmpeg_cmd)\n",
    "\n",
    "    return {\n",
    "        \"video\": str(sanitized_path),\n",
    "        \"transcript\": str(transcript_path) if transcript_path and transcript_path.exists() else None,\n",
    "        \"metadata\": metadata,\n",
    "    }\n",
    "\n",
    "async def generate_and_save_croissant_metadata(row_data: dict) -> str:\n",
    "    if not CROISSANT_AVAILABLE:\n",
    "        return \"N/A (croissant library not installed)\"\n",
    "    try:\n",
    "        fields = [\n",
    "            cnodes.Field(name=\"id\", description=\"Video ID.\", data_types=DataType.TEXT),\n",
    "            cnodes.Field(name=\"link\", description=\"URL to the video.\", data_types=DataType.URL),\n",
    "            cnodes.Field(name=\"caption\", description=\"Original caption.\", data_types=DataType.TEXT),\n",
    "            cnodes.Field(name=\"videocontext\", description=\"AI summary.\", data_types=DataType.TEXT),\n",
    "            cnodes.Field(name=\"politicalbias\", description=\"AI score for political bias.\", data_types=DataType.INTEGER),\n",
    "            cnodes.Field(name=\"criticism\", description=\"AI score for criticism.\", data_types=DataType.INTEGER),\n",
    "            cnodes.Field(name=\"disinfo_level\", description=\"Disinfo classification.\", data_types=DataType.TEXT),\n",
    "        ]\n",
    "        temp_csv = io.StringIO()\n",
    "        writer = csv.DictWriter(temp_csv, fieldnames=[f.name for f in fields], extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerow(row_data)\n",
    "        record_set = cnodes.RecordSet(name=\"video_metadata\", fields=fields, data=temp_csv.getvalue())\n",
    "        video_id = row_data.get('id', 'unknown')\n",
    "        timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        croissant_metadata = Metadata(name=f\"vchat-label-{video_id}\", record_sets=[record_set])\n",
    "        metadata_path = Path(\"metadata\") / f\"{video_id}_{timestamp}.json\"\n",
    "        json_content = croissant_metadata.to_json()\n",
    "        await asyncio.get_event_loop().run_in_executor(None, lambda: metadata_path.write_text(json.dumps(json_content, indent=2)))\n",
    "        return str(metadata_path)\n",
    "    except Exception as e:\n",
    "        return f\"Error generating metadata: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Authentication & Configuration\n",
    "\n",
    "Now, let's configure the model and provide the necessary credentials.\n",
    "\n",
    "**‚û°Ô∏è Action Required**: \n",
    "1. Choose which cloud model to use (`MODEL_SELECTION`).\n",
    "2. Fill in the `VIDEO_URL`.\n",
    "3. Provide credentials for your chosen model:\n",
    "    *   **For Gemini**: Click the **Key icon (üîë)** in the left sidebar, add a new secret named `GEMINI_API_KEY`, and paste your key there. Get one from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
    "    *   **For Vertex AI**: You will be prompted to log in to your Google account when you run the cell. Make sure to fill in your `VERTEX_PROJECT_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata, auth\n",
    "import pprint\n",
    "\n",
    "# Import modules we downloaded earlier\n",
    "from inference_logic import run_gemini_labeling_pipeline, run_vertex_labeling_pipeline\n",
    "\n",
    "# --- USER CONFIGURATION ---\n",
    "\n",
    "# Choose which cloud model to use: 'gemini' or 'vertex'\n",
    "MODEL_SELECTION = 'gemini'\n",
    "\n",
    "# Provide the URL of the video you want to analyze\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=Ad_TEk94B9w\" # Example: A cat playing\n",
    "\n",
    "# --- Credentials (handled by Colab) ---\n",
    "\n",
    "# 1. For Google AI Studio ('gemini') - Fetches from Colab Secrets\n",
    "GEMINI_API_KEY = None\n",
    "GEMINI_MODEL_NAME = \"models/gemini-1.5-pro-latest\"\n",
    "if MODEL_SELECTION == 'gemini':\n",
    "    try:\n",
    "        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "        print(\"Successfully loaded Gemini API Key from Colab Secrets.\")\n",
    "    except userdata.SecretNotFoundError:\n",
    "        print(\"ERROR: Gemini API Key not found. Please add it to Colab Secrets (üîë).\")\n",
    "\n",
    "# 2. For Google Cloud Vertex AI ('vertex')\n",
    "VERTEX_PROJECT_ID = \"your-gcp-project-id-here\"  # <-- IMPORTANT: SET YOUR GCP PROJECT ID\n",
    "VERTEX_LOCATION = \"us-central1\"\n",
    "VERTEX_MODEL_NAME = \"gemini-1.5-pro-preview-0409\"\n",
    "if MODEL_SELECTION == 'vertex':\n",
    "    print(\"Authenticating for Vertex AI... Please follow the pop-up prompt.\")\n",
    "    auth.authenticate_user()\n",
    "    print(\"‚úÖ Vertex AI authentication successful.\")\n",
    "\n",
    "print(\"\\nConfiguration loaded. Ready to run the analysis pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Labeling Pipeline Function\n",
    "\n",
    "The function below encapsulates the entire end-to-end process. It mirrors the exact steps the full web application takes when you click the \"Generate & Append Labels\" button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_full_labeling_pipeline():\n",
    "    \"\"\"Main async function to orchestrate the labeling process.\"\"\"\n",
    "    final_labels = None\n",
    "    csv_row_data = None\n",
    "\n",
    "    # --- Step 1: Prepare Video Assets ---\n",
    "    print(f\"\\n--- [Step 1] Preparing Assets for: {VIDEO_URL} ---\")\n",
    "    paths = await prepare_video_assets_async(VIDEO_URL)\n",
    "    video_path = paths.get(\"video\")\n",
    "    transcript_path = paths.get(\"transcript\")\n",
    "    metadata = paths.get(\"metadata\", {})\n",
    "    print(f\"  -> Video processed and saved to: {video_path}\")\n",
    "    print(f\"  -> Transcript found at: {transcript_path}\")\n",
    "    print(f\"  -> Extracted Metadata: {metadata}\")\n",
    "\n",
    "    # --- Step 2: Prepare Context for the Model ---\n",
    "    print(\"\\n--- [Step 2] Preparing Textual Context ---\")\n",
    "    caption = metadata.get(\"caption\", \"No caption available.\")\n",
    "    transcript_text = \"No transcript available.\" \n",
    "    if transcript_path and Path(transcript_path).exists():\n",
    "        transcript_text = parse_vtt(transcript_path)\n",
    "    print(\"  -> Caption and transcript are ready.\")\n",
    "\n",
    "    # --- Step 3: Run Cloud-Based Labeling ---\n",
    "    print(f\"\\n--- [Step 3] Running Labeling with '{MODEL_SELECTION.capitalize()}' Model ---\")\n",
    "    \n",
    "    pipeline_generator = None\n",
    "    if MODEL_SELECTION == 'gemini':\n",
    "        if not GEMINI_API_KEY: \n",
    "            print(\"ERROR: Cannot proceed without a Gemini API Key.\")\n",
    "            return\n",
    "        gemini_config = {\"api_key\": GEMINI_API_KEY, \"model_name\": GEMINI_MODEL_NAME}\n",
    "        pipeline_generator = run_gemini_labeling_pipeline(video_path, caption, transcript_text, gemini_config, include_comments=True)\n",
    "    elif MODEL_SELECTION == 'vertex':\n",
    "        vertex_config = {\"project_id\": VERTEX_PROJECT_ID, \"location\": VERTEX_LOCATION, \"model_name\": VERTEX_MODEL_NAME, \"api_key\": None}\n",
    "        pipeline_generator = run_vertex_labeling_pipeline(video_path, caption, transcript_text, vertex_config, include_comments=True)\n",
    "    else:\n",
    "        print(f\"ERROR: Invalid model selection '{MODEL_SELECTION}'. Choose 'gemini' or 'vertex'.\")\n",
    "        return\n",
    "\n",
    "    # The pipeline yields progress messages and finally the result dictionary\n",
    "    async for message in pipeline_generator:\n",
    "        if isinstance(message, dict): # This is the final result\n",
    "            final_labels = message\n",
    "        elif isinstance(message, str): # This is a progress update\n",
    "            print(f\"  -> {message.strip()}\")\n",
    "\n",
    "    if not final_labels:\n",
    "        print(\"\\nERROR: Failed to retrieve labels from the model.\")\n",
    "        return\n",
    "\n",
    "    # --- Step 4: Display Parsed Results ---\n",
    "    print(\"\\n--- [Step 4] Successfully Parsed JSON Labels ---\")\n",
    "    pprint.pprint(final_labels)\n",
    "    \n",
    "    # --- Step 5: Generate Croissant Metadata ---\n",
    "    print(\"\\n--- [Step 5] Generating Croissant Metadata File ---\")\n",
    "    # Recreate the data structure expected by the metadata function\n",
    "    def get_score(value):\n",
    "        return value.get('score', '') if isinstance(value, dict) else value\n",
    "\n",
    "    disinfo_analysis = final_labels.get(\"disinformation_analysis\", {})\n",
    "    sentiment_tactics = disinfo_analysis.get(\"sentiment_and_bias_tactics\", {})\n",
    "    \n",
    "    csv_row_data = {\n",
    "        \"id\": metadata.get(\"id\", \"\"),\n",
    "        \"link\": metadata.get(\"link\", VIDEO_URL),\n",
    "        \"caption\": caption,\n",
    "        \"videocontext\": final_labels.get(\"video_context_summary\", \"\"),\n",
    "        \"politicalbias\": get_score(final_labels.get(\"political_bias\", \"\")),\n",
    "        \"criticism\": get_score(final_labels.get(\"criticism_level\", \"\")),\n",
    "        \"videoaudiopairing\": get_score(final_labels.get(\"video_audio_pairing\", \"\")),\n",
    "        \"videocaptionpairing\": get_score(final_labels.get(\"video_caption_pairing\", \"\")),\n",
    "        \"audiocaptionpairing\": get_score(final_labels.get(\"audio_caption_pairing\", \"\")),\n",
    "        \"disinfo_level\": disinfo_analysis.get(\"disinformation_level\", \"\"),\n",
    "        \"disinfo_intent\": disinfo_analysis.get(\"disinformation_intent\", \"\"),\n",
    "        \"disinfo_threat_vector\": disinfo_analysis.get(\"threat_vector\", \"\"),\n",
    "        \"disinfo_emotional_charge\": sentiment_tactics.get(\"emotional_charge\", \"\"),\n",
    "    }\n",
    "    \n",
    "    metadata_path = await generate_and_save_croissant_metadata(csv_row_data)\n",
    "    print(f\"  -> Metadata file saved to: {metadata_path}\")\n",
    "    print(\"\\n--- Pipeline Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the Pipeline\n",
    "\n",
    "Now, we execute the main function. This will trigger the video download, API calls, and processing. You will see real-time progress updates printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(run_full_labeling_pipeline())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}