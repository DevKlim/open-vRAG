<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>vChat Factuality Agent</title>
    <link rel="stylesheet" href="{{ url_for('static', path='/style.css') }}">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@500;700&family=Open+Sans:wght@400;500&display=swap" rel="stylesheet">
</head>
<body>
    <div class="main-container">
        <!-- Left Panel: All user controls and settings -->
        <div class="controls-panel">
            <header class="panel-header">
                <h1>vChat Agent</h1>
                <p class="subtitle">AI-powered analysis for social media videos</p>
            </header>

            <form id="vchat-form" novalidate>
                <section class="control-group">
                    <label for="video_url">Video Source (for Single Analysis)</label>
                    <input type="text" id="video_url" name="video_url" value="https://www.youtube.com/watch?v=XHTskNem4co" placeholder="e.g., https://youtube.com/watch?v=..." required>
                </section>

                <section class="control-group">
                    <label for="model_selection">Execution Model</label>
                    <select id="model_selection" name="model_selection">
                        <option value="default">Default Local Model</option>
                        <option value="gemini">Google AI Studio (API Key)</option>
                        <option value="vertex">Google Cloud Vertex AI (GCP Project)</option>
                        {% if custom_model_available %}
                        <option value="custom">Custom Fine-tuned Model</option>
                        {% endif %}
                    </select>
                     {% if not custom_model_available %}
                        <small>Run `finetune.py` to enable the custom model option.</small>
                    {% endif %}
                </section>

                <div id="gemini-options" class="control-group collapsible-section">
                    <div class="options-grid">
                        <div>
                            <label for="gemini_api_key">Google AI API Key</label>
                            <input type="password" id="gemini_api_key" name="gemini_api_key" placeholder="Enter your API key">
                        </div>
                        <div>
                            <label for="gemini_model_name">Model Name</label>
                            <input type="text" id="gemini_model_name" name="gemini_model_name" value="models/gemini-1.5-pro-latest">
                        </div>
                    </div>
                </div>

                <div id="vertex-options" class="control-group collapsible-section">
                    <div class="options-grid">
                        <div>
                            <label for="vertex_project_id">GCP Project ID</label>
                            <input type="text" id="vertex_project_id" name="vertex_project_id" value="DeepContextGraph">
                        </div>
                        <div>
                            <label for="vertex_api_key">API Key (Optional)</label>
                            <input type="password" id="vertex_api_key" name="vertex_api_key" placeholder="Overrides gcloud auth">
                        </div>
                    </div>
                     <div class="control-group" style="margin-top: 1rem;">
                        <label for="vertex_model_name">Vertex Model Name</label>
                        <div class="options-grid">
                            <input type="text" id="vertex_model_name" name="vertex_model_name" value="gemini-1.5-pro-preview-0409">
                            <input type="text" id="vertex_location" name="vertex_location" value="us-central1">
                        </div>
                    </div>
                    <small>Requires a GCP Project ID. Authentication uses an API Key (if provided) or falls back to Application Default Credentials (e.g., `gcloud auth application-default login`).</small>
                </div>

                <!-- Tabs for different tasks -->
                <div class="tabs">
                    <button type="button" class="tab-link active" data-tab="qa">Q&A & Factuality</button>
                    <button type="button" class="tab-link" data-tab="labeling">Single Video Labeling</button>
                    <button type="button" class="tab-link" data-tab="batch">Batch Auto-Labeling</button>
                </div>
                
                <div class="control-group" id="labeling-options" style="display: none;">
                    <div class="checkbox-group">
                        <input type="checkbox" id="include_comments" name="include_comments" value="true" checked>
                        <label for="include_comments">Include reasoning for each score</label>
                    </div>
                    <small>Generates a detailed JSON file with justifications in `data/labels/`.</small>
                </div>

                <!-- Tab Content -->
                <div id="qa-tab" class="tab-content active">
                    <div class="control-group">
                        <label for="question">Question</label>
                        <textarea id="question" name="question" rows="3" placeholder="e.g., What is the main activity in the video?">What is the animal in the video doing?</textarea>
                        <small>Used for general Q&A. Ignored if a factuality check is active.</small>
                    </div>
                     <details class="advanced-options">
                        <summary>Factuality & Credibility Checks</summary>
                        <p class="form-sub-label">Run automated checks. This will run instead of the general Q&A.</p>
                        <fieldset id="factuality-checks">
                            <div class="checkbox-group"><input type="checkbox" id="check_visuals" name="check_visuals" value="true"><label for="check_visuals">Visual Artifacts</label></div>
                            <div class="checkbox-group"><input type="checkbox" id="check_content" name="check_content" value="true"><label for="check_content">Content Credibility</label></div>
                            <div class="checkbox-group"><input type="checkbox" id="check_audio" name="check_audio" value="true"><label for="check_audio">Audio Anomalies</label></div>
                        </fieldset>
                    </details>
                </div>
                
                <div id="labeling-tab" class="tab-content">
                     <p class="form-sub-label">Automatically generate labels for the single video in 'Video Source' and append the result to `data/dataset.csv`. This task requires Google AI Studio or Vertex AI.</p>
                </div>

                <div id="batch-tab" class="tab-content">
                    <div class="control-group">
                        <label for="csv_file">Upload CSV for Batch Labeling</label>
                        <input type="file" id="csv_file" name="csv_file" accept=".csv">
                        <small>
                            Upload a CSV with a 'link' column. The process will add new, fully-labeled records to a persistent <strong>`data/dataset.csv`</strong> file.
                            <br>It will automatically skip any links that have already been processed in that file.
                            <br><strong>This feature requires Google AI Studio or Vertex AI.</strong>
                        </small>
                    </div>
                </div>


                 <details id="local-model-settings" class="advanced-options">
                    <summary>Advanced Local Model Settings</summary>
                    <div class="options-grid">
                        <div class="form-group"><label for="num_perceptions">Iterations</label><input type="number" id="num_perceptions" name="num_perceptions" value="3" min="1" max="10"></div>
                        <div class="form-group"><label for="max_new_tokens">Max Tokens</label><input type="number" id="max_new_tokens" name="max_new_tokens" value="2048" min="1" step="64"></div>
                        <div class="form-group"><label for="temperature">Temp</label><input type="number" id="temperature" name="temperature" value="0.7" min="0.0" max="2.0" step="0.1"></div>
                        <div class="form-group"><label for="top_p">Top-P</label><input type="number" id="top_p" name="top_p" value="0.9" min="0.0" max="1.0" step="0.05"></div>
                         <div class="form-group"><label for="repetition_penalty">Rep. Penalty</label><input type="number" id="repetition_penalty" name="repetition_penalty" value="1.1" min="1.0" max="2.0" step="0.05"></div>
                        <div class="form-group"><label for="sampling_fps">Sampling FPS</label><input type="number" id="sampling_fps" name="sampling_fps" value="0.2" min="0.01" max="30.0" step="0.01"></div>
                    </div>
                    <div class="form-group"><label for="prompt_glue">Iterative Prompt</label><textarea id="prompt_glue" name="prompt_glue" rows="4">Answer the question: "[QUESTION]" according to the content of the video. 
Output your think process within the <think> </think> tags.
Then, provide your answer within the <answer> </answer> tags. At the same time, in the <glue> </glue> tags, present the precise time period in seconds of the video clips on which you base your answer in the format of [(s1, e1), (s2, e2), ...]. For example: <think>...</think><answer>A</answer><glue>[(5.2, 10.4)]</glue>.</textarea></div>
                    <div class="form-group"><label for="prompt_final">Final Prompt</label><textarea id="prompt_final" name="prompt_final" rows="4">Answer the question: "[QUESTION]" according to the content of the video.
Output your think process within the <think> </think> tags.
Then, provide your answer within the <answer> </answer> tags. For example: <think>...</think><answer>A</answer>.</textarea></div>
                </details>
            </form>

            <div class="panel-footer">
                <button type="submit" id="submit-btn" form="vchat-form">Run Analysis</button>
            </div>
        </div>

        <!-- Right Panel: Displays all output logs -->
        <div class="output-panel">
            <div class="log-header">
                <h2 id="log-title">Output Log</h2>
                <button id="clear-log-btn" title="Clear Log">Clear</button>
            </div>
            <pre id="output-log">Welcome! Select a model and task to begin.</pre>
        </div>
    </div>

    <script>
        // --- DOM Element References ---
        const form = document.getElementById('vchat-form');
        const submitBtn = document.getElementById('submit-btn');
        const outputLog = document.getElementById('output-log');
        const logTitle = document.getElementById('log-title');
        const clearLogBtn = document.getElementById('clear-log-btn');

        const modelSelection = document.getElementById('model_selection');
        const geminiOptions = document.getElementById('gemini-options');
        const vertexOptions = document.getElementById('vertex-options');
        const geminiApiKeyInput = document.getElementById('gemini_api_key');
        const geminiModelNameInput = document.getElementById('gemini_model_name');
        const vertexProjectIdInput = document.getElementById('vertex_project_id');
        const localModelSettings = document.getElementById('local-model-settings');

        const csvFileInput = document.getElementById('csv_file');
        const videoUrlInput = document.getElementById('video_url');
        const questionInput = document.getElementById('question');

        const tabs = document.querySelectorAll('.tab-link');
        const tabContents = document.querySelectorAll('.tab-content');
        const labelingOptions = document.getElementById('labeling-options');
        let activeTab = 'qa';

        // --- Event Listeners ---
        document.addEventListener('DOMContentLoaded', initialize);
        modelSelection.addEventListener('change', handleModelChange);
        tabs.forEach(tab => tab.addEventListener('click', handleTabClick));
        form.addEventListener('submit', handleFormSubmit);
        clearLogBtn.addEventListener('click', () => {
            outputLog.textContent = 'Log cleared.';
        });

        // --- Functions ---
        function initialize() {
            readUrlParams();
            handleModelChange();
            const initialActiveTab = document.querySelector('.tab-link.active');
            if (initialActiveTab) {
                handleTabClick({ target: initialActiveTab });
            }
        }

        function handleTabClick(event) {
            activeTab = event.target.dataset.tab;
            tabs.forEach(tab => tab.classList.remove('active'));
            event.target.classList.add('active');
            tabContents.forEach(content => content.classList.remove('active'));
            document.getElementById(`${activeTab}-tab`).classList.add('active');
            
            labelingOptions.style.display = (activeTab === 'labeling' || activeTab === 'batch') ? 'block' : 'none';
            
            handleModelChange(); // Re-evaluate settings visibility
        }

        function handleModelChange() {
            const model = modelSelection.value;
            const isGemini = model === 'gemini';
            const isVertex = model === 'vertex';
            const isCloud = isGemini || isVertex;
            
            geminiOptions.style.display = isGemini ? 'block' : 'none';
            vertexOptions.style.display = isVertex ? 'block' : 'none';
            localModelSettings.style.display = isCloud || activeTab === 'batch' || activeTab === 'labeling' ? 'none' : 'block';
            updateSubmitButton();
        }

        function updateSubmitButton() {
             const model = modelSelection.value;
             if ((activeTab === 'labeling' || activeTab === 'batch') && (model !== 'gemini' && model !== 'vertex')) {
                submitBtn.textContent = 'Switch to Google Cloud Model to Run';
                submitBtn.disabled = true;
            } else {
                 let text = 'Run Analysis';
                 if (activeTab === 'batch') text = 'Run Batch Labeling';
                 if (activeTab === 'labeling') text = 'Generate & Append Labels';
                 submitBtn.textContent = text;
                 submitBtn.disabled = false;
            }
        }

        function readUrlParams() {
            const params = new URLSearchParams(window.location.search);
            if (params.has('gemini_api_key')) {
                geminiApiKeyInput.value = params.get('gemini_api_key');
                modelSelection.value = 'gemini';
            }
            if (params.has('gemini_model_name')) {
                geminiModelNameInput.value = params.get('gemini_model_name');
            }
        }

        async function handleFormSubmit(event) {
            event.preventDefault();
            let endpoint = '';
            const formData = new FormData(form);
            const model = modelSelection.value;
            
            if (activeTab === 'qa') {
                endpoint = '/process';
                logTitle.textContent = 'Q&A / Factuality Log';
                if (!videoUrlInput.value) {
                    alert('Please provide a Video Source for this task.');
                    return;
                }
            } else if (activeTab === 'batch') {
                endpoint = '/batch_label';
                logTitle.textContent = 'Batch Auto-Labeling Log';
                 if (!csvFileInput.files || csvFileInput.files.length === 0) {
                    alert('Please select a CSV file for batch labeling.');
                    return;
                }
                 if (model === 'gemini' && !geminiApiKeyInput.value) {
                    alert('Batch labeling with Google AI Studio requires an API Key.');
                    return;
                 }
                 if (model === 'vertex' && !vertexProjectIdInput.value) {
                    alert('Batch labeling with Vertex AI requires a GCP Project ID.');
                    return;
                 }
            } else if (activeTab === 'labeling') {
                endpoint = '/label_video';
                logTitle.textContent = 'Single Video Labeling Log';
                if (!videoUrlInput.value) {
                    alert('Please provide a Video Source for labeling.');
                    return;
                }
                 if (model === 'gemini' && !geminiApiKeyInput.value) {
                    alert('Auto-Labeling with Google AI Studio requires an API key.');
                    return;
                 }
                 if (model === 'vertex' && !vertexProjectIdInput.value) {
                    alert('Auto-Labeling with Vertex AI requires a GCP Project ID.');
                    return;
                 }
            }

            setLoadingState(true);

            try {
                const response = await fetch(endpoint, { method: 'POST', body: formData });
                if (!response.ok) {
                    throw new Error(`Server Error: ${response.status} ${response.statusText}\n${await response.text()}`);
                }
                await handleStream(response);
            } catch (error) {
                console.error(`Error during '${activeTab}' task:`, error);
                outputLog.textContent += `\n\n[CLIENT-SIDE ERROR]\n${error.message}`;
            } finally {
                setLoadingState(false);
            }
        }
        
        function setLoadingState(isLoading) {
            if (isLoading) {
                submitBtn.disabled = true;
                submitBtn.textContent = 'Processing...';
                outputLog.textContent = 'Initializing request...';
            } else {
                updateSubmitButton();
            }
        }

        async function handleStream(response) {
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            outputLog.textContent = ''; // Clear previous log
            let buffer = '';

            while (true) {
                const { value, done } = await reader.read();
                if (done) break;

                buffer += decoder.decode(value, { stream: true });
                const messages = buffer.split('\n\n');
                buffer = messages.pop() || '';

                for (const message of messages) {
                    if (message.startsWith('event: close')) return;

                    if (message.startsWith('data:')) {
                        let data = message.substring(5).trim();
                        if (data.includes('\r')) {
                            const lines = outputLog.textContent.split('\n');
                            lines[lines.length - 1] = data.replace(/\r/g, '');
                            outputLog.textContent = lines.join('\n');
                        } else {
                            outputLog.textContent += data + '\n';
                        }
                        outputLog.scrollTop = outputLog.scrollHeight;
                    }
                }
            }
             // Process any remaining data in the buffer
            if (buffer.startsWith('data:')) {
                outputLog.textContent += buffer.substring(5).trim() + '\n';
                outputLog.scrollTop = outputLog.scrollHeight;
            }
        }
    </script>
</body>
</html>
